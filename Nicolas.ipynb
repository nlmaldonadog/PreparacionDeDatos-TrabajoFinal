{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del dataset actual de entrenamiento:  (743024, 32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.impute import IterativeImputer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "import seaborn as sns\n",
    "\n",
    "columns = [\n",
    "    'Base year',\n",
    "    'Subscriber serial number',\n",
    "    'attempt code',\n",
    "    'gender code',\n",
    "    'Age code (5 years increments)',\n",
    "    'Height (in 5cm increments)',\n",
    "    'Weight (in 5 kg units)',\n",
    "    'Waist circumference',\n",
    "    'Vision (left)',\n",
    "    'Vision (right)',\n",
    "    'Hearing (left)',\n",
    "    'Hearing (right)',\n",
    "    'systolic blood pressure',\n",
    "    'diastolic blood pressure',\n",
    "    'Pre-meal blood sugar (fasting blood sugar)',\n",
    "    'total cholesterol',\n",
    "    'triglycerides',\n",
    "    'Cholesterol (HDL)',\n",
    "    'Cholesterol (LDL)',\n",
    "    'hemoglobin',\n",
    "    'urine protein',\n",
    "    'Serum creatinine',\n",
    "    'Liver function test (AST)',\n",
    "    'Liver function test (ALT)',\n",
    "    'Gamma GT',\n",
    "    'Smoking status',\n",
    "    'Drinking status',\n",
    "    'Whether to undergo oral examination',\n",
    "    'Presence of dental caries',\n",
    "    'Whether or not the defect is healed',\n",
    "    'Presence or absence of tooth wear',\n",
    "    'Third molars (wisdom teeth) or more',\n",
    "    'tartar'\n",
    "]\n",
    "df_original = pd.read_csv('Smoking/data-kor.CSV', encoding='cp949', names=columns, skiprows=1)\n",
    "\n",
    "edades = [\n",
    "    [1, '0-1'],\n",
    "    [2, '1-4'],\n",
    "    [3, '5-9'],\n",
    "    [4, '10-14'],\n",
    "    [5, '15-19'],\n",
    "    [6, '20-24'],\n",
    "    [7, '25-29'],\n",
    "    [8, '30-34'],\n",
    "    [9, '35-39'],\n",
    "    [10, '40-44'],\n",
    "    [11, '45-49'],\n",
    "    [12, '50-54'],\n",
    "    [13, '55-59'],\n",
    "    [14, '60-64'],\n",
    "    [15, '65-69'],\n",
    "    [16, '70-74'],\n",
    "    [17, '75-79'],\n",
    "    [18, '80-mas']\n",
    "]\n",
    "\n",
    "edad = pd.DataFrame(edades, columns=['Age code (5 years increments)', 'Age'])\n",
    "df_original = df_original.merge(edad, on='Age code (5 years increments)', how='left')\n",
    "df_original.drop('Age code (5 years increments)', axis=1, inplace=True)\n",
    "\n",
    "df_original_Base = df_original.dropna(subset=['Drinking status'])\n",
    "\n",
    "col_categoricas = ['gender code', \n",
    "                    'Hearing (left)', \n",
    "                    'Hearing (right)', \n",
    "                    'urine protein', \n",
    "                    'Smoking status', \n",
    "                    'Whether to undergo oral examination']\n",
    "col_numericas = ['Height (in 5cm increments)',\n",
    "                          'Weight (in 5 kg units)', \n",
    "                          'Waist circumference',\n",
    "                          'Vision (left)', \n",
    "                          'Vision (right)', \n",
    "                          'systolic blood pressure', \n",
    "                          'diastolic blood pressure', \n",
    "                          'Pre-meal blood sugar (fasting blood sugar)', \n",
    "                          'hemoglobin', \n",
    "                          'Serum creatinine', \n",
    "                          'Liver function test (AST)', \n",
    "                          'Liver function test (ALT)', \n",
    "                          'Gamma GT']\n",
    "\n",
    "# Para el DataFrame original\n",
    "X_original = df_original_Base.drop('Drinking status', axis=1)\n",
    "X_original['stratify_col'] = df_original_Base['Drinking status'].astype(str) + '_' + df_original_Base['gender code'].astype(str)\n",
    "Y_original = df_original_Base['Drinking status']\n",
    "\n",
    "# Para el DataFrame original\n",
    "X_train_orig, X_test_orig, Y_train_orig, Y_test_orig = train_test_split(\n",
    "    X_original, Y_original, test_size=0.2, stratify=X_original['stratify_col'], random_state=42)\n",
    "\n",
    "# Eliminar la columna 'stratify_col' después de dividir los datos\n",
    "X_train_orig = X_train_orig.drop('stratify_col', axis=1)\n",
    "X_test_orig = X_test_orig.drop('stratify_col', axis=1)\n",
    "\n",
    "# Calcula la media y la desviación estándar para cada columna\n",
    "mean = X_train_orig[col_numericas].mean()\n",
    "std = X_train_orig[col_numericas].std()\n",
    "\n",
    "# Define los límites para los outliers\n",
    "lower_bound = mean - 3 * std\n",
    "upper_bound = mean + 3 * std\n",
    "\n",
    "# Identifica los outliers\n",
    "outliers = (X_train_orig[col_numericas] < lower_bound) | (X_train_orig[col_numericas] > upper_bound)\n",
    "mask_no_outliers = (outliers.sum(axis=1) == 0)\n",
    "X_train_orig_sin_outliers_std = X_train_orig[mask_no_outliers]\n",
    "Y_train_orig_sin_outliers_std = Y_train_orig[mask_no_outliers]\n",
    "\n",
    "print('Tamaño del dataset actual de entrenamiento: ', X_train_orig_sin_outliers_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados para datos con LogisticRegression:\n",
      "Accuracy: 0.714 (+/- 0.003)\n"
     ]
    }
   ],
   "source": [
    "transformer = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('age', Pipeline(steps=[('ordinal', OrdinalEncoder(categories = [[i[1] for i in edades]])), ('imputer', SimpleImputer(strategy='most_frequent'))]), ['Age']),\n",
    "                    ('Categoricas', SimpleImputer(strategy='most_frequent'), col_categoricas),\n",
    "                    ('numericas', IterativeImputer(initial_strategy='constant'), col_numericas)\n",
    "                ], remainder='drop')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "pipeline = Pipeline(steps=[('preprocessor', transformer), ('model', LogisticRegression(max_iter=1000))])\n",
    "pipeline_copy = clone(pipeline)\n",
    "\n",
    "scores = cross_val_score(pipeline_copy, X_train_orig_sin_outliers_std, Y_train_orig_sin_outliers_std, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(f'Resultados para datos con {pipeline.steps[1][1].__class__.__name__}:')\n",
    "print(f'Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_transformed = clone(transformer)\n",
    "X_train_sin_out_imputed = copy_transformed.fit_transform(X_train_orig_sin_outliers_std)\n",
    "columnas = ['age'] + col_categoricas + col_numericas\n",
    "X_train_sin_out_imputed = pd.DataFrame(X_train_sin_out_imputed, columns=columnas)\n",
    "\n",
    "print(X_train_orig_sin_outliers_std.head(5))\n",
    "print(X_train_sin_out_imputed.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "escaladores = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "\n",
    "for i, x in enumerate(escaladores):\n",
    "\n",
    "    scaler = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('scaler',  X_train_orig_sin_outliers_std, col_numericas),\n",
    "                ], remainder='passthrough')\n",
    "    pipeline = Pipeline(steps=[('scaler_x', scaler), ('model', LogisticRegression(max_iter=1000))])\n",
    "    scores = cross_val_score(pipeline, X_train_orig_sin_outliers_std, Y_train_orig_sin_outliers_std, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    print(f'Resultados para datos con {pipeline.steps[1][1].__class__.__name__}:')\n",
    "    print(f'Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tecnicas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
